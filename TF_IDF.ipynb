{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus(말뭉치)\n",
        "- 자연어 처리 작업에서 사용하는 텍스트 데이터의 집합을 의미함.\n",
        "- 주로 문장, 문서, 대화 형태의 텍스트로 구성됨.\n",
        "- 용도: 모델을 훈련할 때, 입력으로 사용되며, 특정 언어의 문법, 표현 방식, 단어 사용 빈도를 분석하는데 활용됨.\n",
        "- 특징: 크기나 도메인에 따라 다를 수 있으며, 단일 텍스트가 아니라 다양한 텍스트로 구성된 데이터 셋이다.\n",
        "\n",
        "# Vocab\n",
        "- 주어진 Corpus에서 등장하는 고유한 단어들의 목록임.\n",
        "- Corpus에서 사용된 모든 단어의 모음을 정리한 것(중복 제외됨.)\n",
        "- ex) [\"cat\", \"dog\", \"sleep\"]\n",
        "- 용도: 모델이 텍스트를 처리할 때, Vocab을 참조하여 단어들을 인덱싱하고, 이를 바탕으로 단어의 의미를 파악하거나 예측함.\n",
        "- 특징\n",
        "- 1. Corpus에서 중복을 제거한 고유한 단어들만 포함되므로 크기가 더 작다\n",
        "- 2. 모델의 성능을 높이기 위해 자주 사용되지 않는 단어는 제외하고 일부 단어만 포함하는 경우도 있다.(불용어 제거 후 사용할 때도 있음.)\n",
        "\n",
        "# Lexicon\n",
        "- 특정 언어의 단어 목록 또는 특정 도메인에서 사용되는 용어들의 특징 집합을 말함.\n",
        "- 단순한 어휘 목록이 아니라 특정 단어와 그 단어에 대한 구체적인 정보가 포함된 일종의 어휘 사전이라고 할 수 있음.\n",
        "- ex) ('apple', 'n')\n",
        "\n",
        "\n",
        "# 단어 출현 빈도를 활용한 벡터화\n",
        "- 특정 문장이나 문서를 그 의미에 따라 벡터화하기 위한 방법 중 하나로서 bag-of-words처럼 어떤 단어들이 많이 등장하고 어떤 단어들이 적게 등장헀는지를 활용할 수 있다.\n",
        "- ex) 특정 분야에 대한 문서는 관련 전문 용어가 다른 분야의 문서에서보다 훨씬 많이 등장할 확률이 높다.\n",
        "- (문제 발생) 단어의 출현 횟수만으로 문장이나 문서를 벡터로 나타낸다면 문장, 문서의 길이가 제각각이기 때문에 긴 문장에서와 짧은 문장에서의 벡터값 분포가 매우 달라진다.\n",
        "- (문제 해결) 따라서 bag-of-words를 전체 문장, 문서 길이에 대해 정규화하면 단어 출현 횟수가 아닌 단어 출현 빈도(비율)이 되면 더 우수한 벡터 표현이 된다고 할 수 있다.\n",
        "#TF(Term Frequency)\n",
        "- 단어 출현 횟수 / 전체 토큰 수\n",
        "- 위와 같은 식으로 구한 특정 단어의 출현 빈도를 TF라고 하며, 전통적인 NLP에서의 주요 특징 중 하나로 널리 활용되고 있음.\n",
        "- 출현 횟수(BoW)가 아니라 정규화된 형태인 '출현 빈도'를 사용하는 이유\n",
        "  - 1. 다양한 길이에 대해 문서끼리 비교가 용이함.\n",
        "  - 2. BoW보다 긴 텍스트에서 성능 향상"
      ],
      "metadata": {
        "id": "H54Rmlb6J-Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK를 활용한 문서 토큰화\n",
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "n6y5-oVELuwW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = '''The faster Harry got to the store, the faster Harry, the faster, would get home.'''\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokens = tokenizer.tokenize(sentence.lower())\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knjGqJ3ZL30-",
        "outputId": "690106f3-f378-44ad-bf5d-03530c9c486b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'faster',\n",
              " 'harry',\n",
              " 'got',\n",
              " 'to',\n",
              " 'the',\n",
              " 'store',\n",
              " ',',\n",
              " 'the',\n",
              " 'faster',\n",
              " 'harry',\n",
              " ',',\n",
              " 'the',\n",
              " 'faster',\n",
              " ',',\n",
              " 'would',\n",
              " 'get',\n",
              " 'home',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "bag_of_words = Counter(tokens)\n",
        "bag_of_words.most_common(4) # 기본적으로 most_common()은 모든 토큰을 그 빈도순으로(자주 출현한 것부터) 나열한다. 4로 지정해주었기 때문에 최상위 4개만 출력한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-erTWUkRVUH",
        "outputId": "d2fc72b3-353c-49e1-8fdf-eb30a21dc9ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 4), ('faster', 3), (',', 3), ('harry', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF\n",
        "times_harry_appears = bag_of_words['harry']\n",
        "num_unique_words = len(tokens) # 원 문장에 있는 고유한 토큰의 수\n",
        "tf = times_harry_appears / num_unique_words # term frequency: 특정 단어의 출현\n",
        "round(tf,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJpRGQa1R34t",
        "outputId": "b095598d-c348-4fad-a109-e5c8e5839f53"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0099"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kite 문서 토큰화 및 용어별 출현 횟수 계산\n",
        "# 관사가 최상위에 위치에 있는데 이는 특별한 의미를 담고 있지 않으므로 불용어 제거를 수행하고자 함.\n",
        "from collections import Counter\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()"
      ],
      "metadata": {
        "id": "hfFFpCBKVhF_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kite_text = '''\n",
        "A kite is a tethered heavier-than-air or lighter-than-air craft with wing surfaces that react against the air to create lift and drag forces.\n",
        "A kite consists of wings, tethers and anchors. Kites often have a bridle and tail to guide the face of the kite so the wind can lift it.\n",
        "Some kite designs do not need a bridle; box kites can have a single attachment point.\n",
        "A kite may have fixed or moving anchors that can balance the kite. The name is derived from the kite, the hovering bird of prey.\n",
        "There are several shapes of kites.\n",
        "The lift that sustains the kite in flight is generated when air moves around the kite's surface, producing low pressure above and high pressure below the wings.\n",
        "The interaction with the wind also generates horizontal drag along the direction of the wind.\n",
        "The resultant force vector from the lift and drag force components is opposed by the tension of one or more of the lines or tethers to which the kite is attached.\n",
        "The anchor point of the kite line may be static or moving (e.g., the towing of a kite by a running person, boat, free-falling anchors as in paragliders and fugitive parakites or vehicle).\n",
        "The same principles of fluid flow apply in liquids, so kites can be used in underwater currents.\n",
        "Paravanes and otter boards operate underwater on an analogous principle.\n",
        "Man-lifting kites were made for reconnaissance, entertainment and during development of the first practical aircraft, the biplane.\n",
        "Kites have a long and varied history and many different types are flown individually and at festivals worldwide.\n",
        "Kites may be flown for recreation, art or other practical uses. Sport kites can be flown in aerial ballet, sometimes as part of a competition.\n",
        "Power kites are multi-line steerable kites designed to generate large forces which can be used to power activities such as kite surfing, kite landboarding, kite buggying and snow kiting.\n",
        "'''\n",
        "tokens = tokenizer.tokenize(kite_text.lower())\n",
        "token_counts = Counter(tokens)\n",
        "token_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGeV5mG0Zi6_",
        "outputId": "4886f34e-da92-4499-f0de-20589bd27475"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'a': 11,\n",
              "         'kite': 14,\n",
              "         'is': 5,\n",
              "         'tethered': 1,\n",
              "         'heavier-than-air': 1,\n",
              "         'or': 7,\n",
              "         'lighter-than-air': 1,\n",
              "         'craft': 1,\n",
              "         'with': 2,\n",
              "         'wing': 1,\n",
              "         'surfaces': 1,\n",
              "         'that': 3,\n",
              "         'react': 1,\n",
              "         'against': 1,\n",
              "         'the': 27,\n",
              "         'air': 2,\n",
              "         'to': 5,\n",
              "         'create': 1,\n",
              "         'lift': 4,\n",
              "         'and': 12,\n",
              "         'drag': 3,\n",
              "         'forces.': 1,\n",
              "         'consists': 1,\n",
              "         'of': 12,\n",
              "         'wings': 1,\n",
              "         ',': 13,\n",
              "         'tethers': 2,\n",
              "         'anchors.': 1,\n",
              "         'kites': 9,\n",
              "         'often': 1,\n",
              "         'have': 4,\n",
              "         'bridle': 2,\n",
              "         'tail': 1,\n",
              "         'guide': 1,\n",
              "         'face': 1,\n",
              "         'so': 2,\n",
              "         'wind': 2,\n",
              "         'can': 6,\n",
              "         'it.': 1,\n",
              "         'some': 1,\n",
              "         'designs': 1,\n",
              "         'do': 1,\n",
              "         'not': 1,\n",
              "         'need': 1,\n",
              "         ';': 1,\n",
              "         'box': 1,\n",
              "         'single': 1,\n",
              "         'attachment': 1,\n",
              "         'point.': 1,\n",
              "         'may': 3,\n",
              "         'fixed': 1,\n",
              "         'moving': 2,\n",
              "         'anchors': 2,\n",
              "         'balance': 1,\n",
              "         'kite.': 1,\n",
              "         'name': 1,\n",
              "         'derived': 1,\n",
              "         'from': 2,\n",
              "         'hovering': 1,\n",
              "         'bird': 1,\n",
              "         'prey.': 1,\n",
              "         'there': 1,\n",
              "         'are': 3,\n",
              "         'several': 1,\n",
              "         'shapes': 1,\n",
              "         'kites.': 1,\n",
              "         'sustains': 1,\n",
              "         'in': 5,\n",
              "         'flight': 1,\n",
              "         'generated': 1,\n",
              "         'when': 1,\n",
              "         'moves': 1,\n",
              "         'around': 1,\n",
              "         \"'s\": 1,\n",
              "         'surface': 1,\n",
              "         'producing': 1,\n",
              "         'low': 1,\n",
              "         'pressure': 2,\n",
              "         'above': 1,\n",
              "         'high': 1,\n",
              "         'below': 1,\n",
              "         'wings.': 1,\n",
              "         'interaction': 1,\n",
              "         'also': 1,\n",
              "         'generates': 1,\n",
              "         'horizontal': 1,\n",
              "         'along': 1,\n",
              "         'direction': 1,\n",
              "         'wind.': 1,\n",
              "         'resultant': 1,\n",
              "         'force': 2,\n",
              "         'vector': 1,\n",
              "         'components': 1,\n",
              "         'opposed': 1,\n",
              "         'by': 2,\n",
              "         'tension': 1,\n",
              "         'one': 1,\n",
              "         'more': 1,\n",
              "         'lines': 1,\n",
              "         'which': 2,\n",
              "         'attached.': 1,\n",
              "         'anchor': 1,\n",
              "         'point': 1,\n",
              "         'line': 1,\n",
              "         'be': 5,\n",
              "         'static': 1,\n",
              "         '(': 1,\n",
              "         'e.g.': 1,\n",
              "         'towing': 1,\n",
              "         'running': 1,\n",
              "         'person': 1,\n",
              "         'boat': 1,\n",
              "         'free-falling': 1,\n",
              "         'as': 3,\n",
              "         'paragliders': 1,\n",
              "         'fugitive': 1,\n",
              "         'parakites': 1,\n",
              "         'vehicle': 1,\n",
              "         ')': 1,\n",
              "         '.': 2,\n",
              "         'same': 1,\n",
              "         'principles': 1,\n",
              "         'fluid': 1,\n",
              "         'flow': 1,\n",
              "         'apply': 1,\n",
              "         'liquids': 1,\n",
              "         'used': 2,\n",
              "         'underwater': 2,\n",
              "         'currents.': 1,\n",
              "         'paravanes': 1,\n",
              "         'otter': 1,\n",
              "         'boards': 1,\n",
              "         'operate': 1,\n",
              "         'on': 1,\n",
              "         'an': 1,\n",
              "         'analogous': 1,\n",
              "         'principle.': 1,\n",
              "         'man-lifting': 1,\n",
              "         'were': 1,\n",
              "         'made': 1,\n",
              "         'for': 2,\n",
              "         'reconnaissance': 1,\n",
              "         'entertainment': 1,\n",
              "         'during': 1,\n",
              "         'development': 1,\n",
              "         'first': 1,\n",
              "         'practical': 2,\n",
              "         'aircraft': 1,\n",
              "         'biplane.': 1,\n",
              "         'long': 1,\n",
              "         'varied': 1,\n",
              "         'history': 1,\n",
              "         'many': 1,\n",
              "         'different': 1,\n",
              "         'types': 1,\n",
              "         'flown': 3,\n",
              "         'individually': 1,\n",
              "         'at': 1,\n",
              "         'festivals': 1,\n",
              "         'worldwide.': 1,\n",
              "         'recreation': 1,\n",
              "         'art': 1,\n",
              "         'other': 1,\n",
              "         'uses.': 1,\n",
              "         'sport': 1,\n",
              "         'aerial': 1,\n",
              "         'ballet': 1,\n",
              "         'sometimes': 1,\n",
              "         'part': 1,\n",
              "         'competition.': 1,\n",
              "         'power': 2,\n",
              "         'multi-line': 1,\n",
              "         'steerable': 1,\n",
              "         'designed': 1,\n",
              "         'generate': 1,\n",
              "         'large': 1,\n",
              "         'forces': 1,\n",
              "         'activities': 1,\n",
              "         'such': 1,\n",
              "         'surfing': 1,\n",
              "         'landboarding': 1,\n",
              "         'buggying': 1,\n",
              "         'snow': 1,\n",
              "         'kiting': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 제거 후 the, a 등의 관사가 제거됨을 알 수 있음.\n",
        "import nltk\n",
        "nltk.download('stopwords',quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0smXxBCeaQa",
        "outputId": "c9d3600d-5dfc-406e-bd58-7ebf0575f2e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "tokens = [x for x in tokens if x not in stopwords] # tokens == 전체 토큰, 불용어 제거\n",
        "kite_counts = Counter(tokens) # 불용어를 제거한 전체 토큰\n",
        "kite_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxjqeH_peya2",
        "outputId": "5db45300-9abc-45c1-b732-3a30f8821d8c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'kite': 14,\n",
              "         'tethered': 1,\n",
              "         'heavier-than-air': 1,\n",
              "         'lighter-than-air': 1,\n",
              "         'craft': 1,\n",
              "         'wing': 1,\n",
              "         'surfaces': 1,\n",
              "         'react': 1,\n",
              "         'air': 2,\n",
              "         'create': 1,\n",
              "         'lift': 4,\n",
              "         'drag': 3,\n",
              "         'forces.': 1,\n",
              "         'consists': 1,\n",
              "         'wings': 1,\n",
              "         ',': 13,\n",
              "         'tethers': 2,\n",
              "         'anchors.': 1,\n",
              "         'kites': 9,\n",
              "         'often': 1,\n",
              "         'bridle': 2,\n",
              "         'tail': 1,\n",
              "         'guide': 1,\n",
              "         'face': 1,\n",
              "         'wind': 2,\n",
              "         'it.': 1,\n",
              "         'designs': 1,\n",
              "         'need': 1,\n",
              "         ';': 1,\n",
              "         'box': 1,\n",
              "         'single': 1,\n",
              "         'attachment': 1,\n",
              "         'point.': 1,\n",
              "         'may': 3,\n",
              "         'fixed': 1,\n",
              "         'moving': 2,\n",
              "         'anchors': 2,\n",
              "         'balance': 1,\n",
              "         'kite.': 1,\n",
              "         'name': 1,\n",
              "         'derived': 1,\n",
              "         'hovering': 1,\n",
              "         'bird': 1,\n",
              "         'prey.': 1,\n",
              "         'several': 1,\n",
              "         'shapes': 1,\n",
              "         'kites.': 1,\n",
              "         'sustains': 1,\n",
              "         'flight': 1,\n",
              "         'generated': 1,\n",
              "         'moves': 1,\n",
              "         'around': 1,\n",
              "         \"'s\": 1,\n",
              "         'surface': 1,\n",
              "         'producing': 1,\n",
              "         'low': 1,\n",
              "         'pressure': 2,\n",
              "         'high': 1,\n",
              "         'wings.': 1,\n",
              "         'interaction': 1,\n",
              "         'also': 1,\n",
              "         'generates': 1,\n",
              "         'horizontal': 1,\n",
              "         'along': 1,\n",
              "         'direction': 1,\n",
              "         'wind.': 1,\n",
              "         'resultant': 1,\n",
              "         'force': 2,\n",
              "         'vector': 1,\n",
              "         'components': 1,\n",
              "         'opposed': 1,\n",
              "         'tension': 1,\n",
              "         'one': 1,\n",
              "         'lines': 1,\n",
              "         'attached.': 1,\n",
              "         'anchor': 1,\n",
              "         'point': 1,\n",
              "         'line': 1,\n",
              "         'static': 1,\n",
              "         '(': 1,\n",
              "         'e.g.': 1,\n",
              "         'towing': 1,\n",
              "         'running': 1,\n",
              "         'person': 1,\n",
              "         'boat': 1,\n",
              "         'free-falling': 1,\n",
              "         'paragliders': 1,\n",
              "         'fugitive': 1,\n",
              "         'parakites': 1,\n",
              "         'vehicle': 1,\n",
              "         ')': 1,\n",
              "         '.': 2,\n",
              "         'principles': 1,\n",
              "         'fluid': 1,\n",
              "         'flow': 1,\n",
              "         'apply': 1,\n",
              "         'liquids': 1,\n",
              "         'used': 2,\n",
              "         'underwater': 2,\n",
              "         'currents.': 1,\n",
              "         'paravanes': 1,\n",
              "         'otter': 1,\n",
              "         'boards': 1,\n",
              "         'operate': 1,\n",
              "         'analogous': 1,\n",
              "         'principle.': 1,\n",
              "         'man-lifting': 1,\n",
              "         'made': 1,\n",
              "         'reconnaissance': 1,\n",
              "         'entertainment': 1,\n",
              "         'development': 1,\n",
              "         'first': 1,\n",
              "         'practical': 2,\n",
              "         'aircraft': 1,\n",
              "         'biplane.': 1,\n",
              "         'long': 1,\n",
              "         'varied': 1,\n",
              "         'history': 1,\n",
              "         'many': 1,\n",
              "         'different': 1,\n",
              "         'types': 1,\n",
              "         'flown': 3,\n",
              "         'individually': 1,\n",
              "         'festivals': 1,\n",
              "         'worldwide.': 1,\n",
              "         'recreation': 1,\n",
              "         'art': 1,\n",
              "         'uses.': 1,\n",
              "         'sport': 1,\n",
              "         'aerial': 1,\n",
              "         'ballet': 1,\n",
              "         'sometimes': 1,\n",
              "         'part': 1,\n",
              "         'competition.': 1,\n",
              "         'power': 2,\n",
              "         'multi-line': 1,\n",
              "         'steerable': 1,\n",
              "         'designed': 1,\n",
              "         'generate': 1,\n",
              "         'large': 1,\n",
              "         'forces': 1,\n",
              "         'activities': 1,\n",
              "         'surfing': 1,\n",
              "         'landboarding': 1,\n",
              "         'buggying': 1,\n",
              "         'snow': 1,\n",
              "         'kiting': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈도가 높은 단어 순으로 TF를 벡터 값으로 이용해서 문서를 벡터화 한 결과\n",
        "document_vector = []\n",
        "doc_length = len(tokens)\n",
        "for key, value in kite_counts.most_common(): # 특정 단어 등장 횟수 내림차순\n",
        "  document_vector.append(value / doc_length) # TF = 토큰 출현 횟수 / 총 토큰 갯수(불용어 제거)\n",
        "document_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJn4xptkfKjj",
        "outputId": "194bdaf9-676a-43d8-9353-ec40026cdddf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06930693069306931,\n",
              " 0.06435643564356436,\n",
              " 0.04455445544554455,\n",
              " 0.019801980198019802,\n",
              " 0.01485148514851485,\n",
              " 0.01485148514851485,\n",
              " 0.01485148514851485,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.009900990099009901,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506,\n",
              " 0.0049504950495049506]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 세 문장 유사도 비교\n",
        "docs = [\"The faster Harry got to the store, the faster and faster Harry would get home.\"]\n",
        "docs.append(\"Harry is hairy and faster than Jill.\")\n",
        "docs.append(\"Jill is not as hairy as Harry.\")"
      ],
      "metadata": {
        "id": "t2kHUaZhgMwQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF 벡터 생성에 앞서 vocab 구축\n",
        "doc_tokens = []\n",
        "for doc in docs:\n",
        "  doc_tokens += [sorted(tokenizer.tokenize(doc.lower()))]"
      ],
      "metadata": {
        "id": "aTJ3-9K3hRCV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc_tokens[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HtAezk3DmxA",
        "outputId": "c5c74a31-74ff-4c08-df2d-d4e0cba2ca46"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_doc_tokens = sum(doc_tokens,[])"
      ],
      "metadata": {
        "id": "hLglkeXLDwOZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_doc_tokens) # 총 33개의 토큰 생성"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V24ONmHfDrQ8",
        "outputId": "e0b1cb52-92bf-436d-82ff-c5220919f1eb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(all_doc_tokens)) # 토큰 중복 제거"
      ],
      "metadata": {
        "id": "G_rJMfuYD2wj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7kwq6LJEDgb",
        "outputId": "da4fbf1e-6497-488a-8326-bf18a8006bd8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "248UArQ3EFfj",
        "outputId": "c67238c2-a875-4882-8303-2c4c15a7d5b8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[',',\n",
              " '.',\n",
              " 'and',\n",
              " 'as',\n",
              " 'faster',\n",
              " 'get',\n",
              " 'got',\n",
              " 'hairy',\n",
              " 'harry',\n",
              " 'home',\n",
              " 'is',\n",
              " 'jill',\n",
              " 'not',\n",
              " 'store',\n",
              " 'than',\n",
              " 'the',\n",
              " 'to',\n",
              " 'would']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터를 통한 유사도 계산\n",
        "# 현재 모든 3개의 문서에 등장하는 토큰이 18개 있으므로 각 문서를 표현하기 위해서 18개의 성분을 가진 벡터가 필요\n",
        "# 각 벡터의 성분의 위치(index)에 따라 대응되는 토큰이 동일하게 유지되어야 함.\n",
        "# 같은 벡터 공간 상에서 문서들을 벅터화하여 표현하여야 하며, 아래는 벡터 공간에서의 영벡터 예시임.\n",
        "from collections import OrderedDict\n",
        "zero_vector = OrderedDict((token,0) for token in vocab)\n",
        "zero_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dcDrBP0EHXx",
        "outputId": "a8fbe0f5-6cad-48a0-d693-774b6858fd5f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([(',', 0),\n",
              "             ('.', 0),\n",
              "             ('and', 0),\n",
              "             ('as', 0),\n",
              "             ('faster', 0),\n",
              "             ('get', 0),\n",
              "             ('got', 0),\n",
              "             ('hairy', 0),\n",
              "             ('harry', 0),\n",
              "             ('home', 0),\n",
              "             ('is', 0),\n",
              "             ('jill', 0),\n",
              "             ('not', 0),\n",
              "             ('store', 0),\n",
              "             ('than', 0),\n",
              "             ('the', 0),\n",
              "             ('to', 0),\n",
              "             ('would', 0)])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 문장별로 TF 벡터 계산\n",
        "# 영벡터를 복사한 뒤, 단어 출현 빈도에 대한 벡터 생성\n",
        "# 단어 출현 빈도는 각 단어의 출현 횟수를 해당 문서의 길이로 나누어주어야 함.\n",
        "import copy\n",
        "doc_vectors = []\n",
        "for doc in docs: # 각 문서에 대해서 loop\n",
        "  vec = copy.copy(zero_vector) #  영벡터 복사 -> 독립적인 벡터 생성\n",
        "  tokens = tokenizer.tokenize(doc.lower()) # 토큰화\n",
        "  token_counts = Counter(tokens)\n",
        "  for key, value in token_counts.items():\n",
        "    vec[key] = value / len(tokens) # 각 토큰에 대한 TF 계산\n",
        "  doc_vectors.append(vec)"
      ],
      "metadata": {
        "id": "_bPE0-K9FU5z"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens # 중복 허용된 토큰"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4_AsnjrHMcT",
        "outputId": "deef1f6f-fbad-4b85-890d-2bea5c303b63"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jill', 'is', 'not', 'as', 'hairy', 'as', 'harry', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQM0hc59HmFz",
        "outputId": "4f34551f-69c6-49be-e9cd-10182842c791"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'jill': 1,\n",
              "         'is': 1,\n",
              "         'not': 1,\n",
              "         'as': 2,\n",
              "         'hairy': 1,\n",
              "         'harry': 1,\n",
              "         '.': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec # 각 토큰에 대한 TF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg6rKraCG-UG",
        "outputId": "07b54f36-2bfa-4fff-d40f-8294acb3fa37"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([(',', 0),\n",
              "             ('.', 0.125),\n",
              "             ('and', 0),\n",
              "             ('as', 0.25),\n",
              "             ('faster', 0),\n",
              "             ('get', 0),\n",
              "             ('got', 0),\n",
              "             ('hairy', 0.125),\n",
              "             ('harry', 0.125),\n",
              "             ('home', 0),\n",
              "             ('is', 0.125),\n",
              "             ('jill', 0.125),\n",
              "             ('not', 0.125),\n",
              "             ('store', 0),\n",
              "             ('than', 0),\n",
              "             ('the', 0),\n",
              "             ('to', 0),\n",
              "             ('would', 0)])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlrxXOL3GcAR",
        "outputId": "516d5cb1-609f-494d-e9f4-fed1f434ff04"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[OrderedDict([(',', 0.058823529411764705),\n",
              "              ('.', 0.058823529411764705),\n",
              "              ('and', 0.058823529411764705),\n",
              "              ('as', 0),\n",
              "              ('faster', 0.17647058823529413),\n",
              "              ('get', 0.058823529411764705),\n",
              "              ('got', 0.058823529411764705),\n",
              "              ('hairy', 0),\n",
              "              ('harry', 0.11764705882352941),\n",
              "              ('home', 0.058823529411764705),\n",
              "              ('is', 0),\n",
              "              ('jill', 0),\n",
              "              ('not', 0),\n",
              "              ('store', 0.058823529411764705),\n",
              "              ('than', 0),\n",
              "              ('the', 0.17647058823529413),\n",
              "              ('to', 0.058823529411764705),\n",
              "              ('would', 0.058823529411764705)]),\n",
              " OrderedDict([(',', 0),\n",
              "              ('.', 0.125),\n",
              "              ('and', 0.125),\n",
              "              ('as', 0),\n",
              "              ('faster', 0.125),\n",
              "              ('get', 0),\n",
              "              ('got', 0),\n",
              "              ('hairy', 0.125),\n",
              "              ('harry', 0.125),\n",
              "              ('home', 0),\n",
              "              ('is', 0.125),\n",
              "              ('jill', 0.125),\n",
              "              ('not', 0),\n",
              "              ('store', 0),\n",
              "              ('than', 0.125),\n",
              "              ('the', 0),\n",
              "              ('to', 0),\n",
              "              ('would', 0)]),\n",
              " OrderedDict([(',', 0),\n",
              "              ('.', 0.125),\n",
              "              ('and', 0),\n",
              "              ('as', 0.25),\n",
              "              ('faster', 0),\n",
              "              ('get', 0),\n",
              "              ('got', 0),\n",
              "              ('hairy', 0.125),\n",
              "              ('harry', 0.125),\n",
              "              ('home', 0),\n",
              "              ('is', 0.125),\n",
              "              ('jill', 0.125),\n",
              "              ('not', 0.125),\n",
              "              ('store', 0),\n",
              "              ('than', 0),\n",
              "              ('the', 0),\n",
              "              ('to', 0),\n",
              "              ('would', 0)])]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 벡터를 통한 유사도 계산\n",
        "- 특징점들로 나타낸 벡터들의 유사도를 계산할 때는 벡터들 사이의 각도에 대한 정보에 해당하는 cosine similarity를 주로 활용함.\n",
        "- TF의 경우를 생각해보면 절대 빈도가 아니라 단어들 사이의 TF 비율에 근거해서 유사도를 판단함.\n",
        "- 벡터 공간에서 차원 수는 Vocab의 토큰 개수와 같음.\n",
        "- 거리보다 각도(방향)을 통해 유사도를 측정한다."
      ],
      "metadata": {
        "id": "C7P9DqAaG6H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터를 통한 유사도 계산 구현\n",
        "import math\n",
        "def cosine_sim(vec1, vec2):\n",
        "  '''\n",
        "  두 문서 표현 벡터의 코사인 유사도를 계산하는 함수\n",
        "  '''\n",
        "  vec1 = [val for val in vec1.values()]\n",
        "  vec2 = [val for val in vec2.values()]\n",
        "  dot_prod = 0\n",
        "  for i, v in enumerate(vec1):\n",
        "    dot_prod += v*vec2[i]\n",
        "  mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
        "  mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
        "\n",
        "  return dot_prod / (mag_1 * mag_2)"
      ],
      "metadata": {
        "id": "L45Wv666Gdxw"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim(doc_vectors[0], doc_vectors[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kkXtU4tTnxT",
        "outputId": "7e0f841e-cf58-45c4-c098-e02741ec92cc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44450044450066667"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim(doc_vectors[0], doc_vectors[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr4u-8teTx6n",
        "outputId": "4a0dedfa-c796-4f86-fee7-78d92e392d4b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1703885502741194"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코사인 유사도는 -1 ~ +1의 값을 가지며, 값이 높을수록 유사도가 높음.\n",
        "# 음수의 경우, 반대 방향임을 의미하며 -1이면 정반대의 방향이라는 뜻임.\n",
        "# 0이면 공통점이 전혀 없다는 것을 의미\n",
        "cosine_sim(doc_vectors[1], doc_vectors[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjSNZx_4T2D5",
        "outputId": "0b909658-b765-40cb-e05d-cb4313570d84"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5590169943749475"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Term Frequency(TF)\n",
        "- TF = 출현 횟수(BoW) / 전체 토큰 수(len(tokens))\n",
        "- 문서의 길이에 따라 정규화하는 것이 아니라 출현 횟수를 전체 우리가 사용하고 있는 어휘의 수와 비교해서 보겠다.\n",
        "\n",
        "# 역문서 빈도(Inverse Document Frequency, IDF)\n",
        "- (문제 발생) TF 자체도 훌륭한 특징점으로 활용할 수 있지만, 어느 문서에서나 유사하게 많이 쓰이는 단어도 있고, 특정 문서에서만 많이 등장하는 단어가 있을 수도 있다. -> 어디서나 많이 쓰이는 단어가 유사도가 높게 나온다.\n",
        "- (문제 해결) IDF 활용, 각 단어에 대해 해당 단어가 출현한 문서 수를 전체 문서 수에 대해 나눈 것으로서, 많은 문서에서 등장하는 단어일수록 IDF 값이 낮아짐.\n",
        "- IDF = 전체 문서 수 / 해당 단어 출현 문서 수\n",
        "- IDF 값이 높을수록 특정 문서에서만 등장하는 단어가 되며 이는 각 문서의 주제를 대표하는 단어일 확룔이 높아짐을 의미함."
      ],
      "metadata": {
        "id": "-rXsXtCEU80N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_text = '''\n",
        "The kite has been claimed as the invention of the 5th-century BC Chinese philosophers Mozi (also Mo Di, or Mo Ti) and Lu Ban (also Gongshu Ban, or Kungshu Phan). Materials ideal for kite building were readily available including silk fabric for sail material; fine, high-tensile-strength silk for flying line; and resilient bamboo for a strong, lightweight framework. By 549 AD, paper kites were certainly being flown, as it was recorded that in that year a paper kite was used as a message for a rescue mission. Ancient and medieval Chinese sources describe kites being used for measuring distances, testing the wind, lifting men, signaling, and communication for military operations. The earliest known Chinese kites were flat (not bowed) and often rectangular.\n",
        "Later, tailless kites incorporated a stabilizing bowline.\n",
        "Kites were decorated with mythological motifs and legendary figures; some were fitted with strings and whistles to make musical sounds while flying.\n",
        "Kite Flying by Suzuki Harunobu, 1766 (Metropolitan Museum of Art)\n",
        "After its introduction into India, the kite further evolved into the fighter kite, known as the patang in India, where thousands are flown every year on festivals such as Makar Sankranti.\n",
        "Kites were known throughout Polynesia, as far as New Zealand, with the assumption being that the knowledge diffused from China along with the people.\n",
        "Anthropomorphic kites made from cloth and wood were used in religious ceremonies to send prayers to the gods.\n",
        "Polynesian kite traditions are used by anthropologists to get an idea of early \"primitive\" Asian traditions that are believed to have at one time existed in Asia.\n",
        "Kites were late to arrive in Europe, although windsock-like banners were known and used by the Romans.\n",
        "Stories of kites were first brought to Europe by Marco Polo towards the end of the 13th century, and kites were brought back by sailors from Japan and Malaysia in the 16th and 17th centuries.\n",
        "Konrad Kyeser described dragon kites in Bellifortis about 1400 AD.\n",
        "Although kites were initially regarded as mere curiosities, by the 18th and 19th centuries they were being used as vehicles for scientific research.\n",
        "Boys flying a kite. Engraving published in Germany in 1828 by Johann Michael Voltz\n",
        "In 1752, Benjamin Franklin published an account of a kite experiment to prove that lightning was caused by electricity.\n",
        "Kites were also instrumental in the research of the Wright brothers, and others, as they developed the first airplane in the late 1800s.\n",
        "Several different designs of man-lifting kites were developed. The period from 1860 to about 1910 became the European \"golden age of kiting\".\n",
        "In the 20th century, many new kite designs are developed. These included Eddy's tailless diamond, the tetrahedral kite, the Rogallo wing, the sled kite, the parafoil, and power kites.\n",
        "Kites were used for scientific purposes, especially in meteorology, aeronautics, wireless communications and photography.\n",
        "The Rogallo wing was adapted for stunt kites and hang gliding and the parafoil was adapted for parachuting and paragliding.\n",
        "The rapid development of mechanically powered aircraft diminished interest in kites.\n",
        "World War II saw a limited use of kites for military purposes (survival radio, Focke Achgelis Fa 330, military radio antenna kites).\n",
        "Kites are now mostly used for recreation.\n",
        "Lightweight synthetic materials (ripstop nylon, plastic film, carbon fiber tube and rod) are used for kite making.\n",
        "Synthetic rope and cord (nylon, polyethylene, kevlar and dyneema) are used as bridle and kite line.\n",
        "'''"
      ],
      "metadata": {
        "id": "XpoyawItYs-M"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 개요 문서\n",
        "intro_text = kite_text.lower()\n",
        "intro_tokens = tokenizer.tokenize(intro_text) # 중복 허용한 토큰 수\n",
        "\n",
        "# 역사 문서\n",
        "history_text = history_text.lower()\n",
        "history_tokens = tokenizer.tokenize(history_text)\n",
        "\n",
        "# 중복 허용한 총 토근 수\n",
        "intro_total = len(intro_tokens)\n",
        "history_total = len(history_tokens)\n",
        "\n",
        "print(intro_total)\n",
        "print(history_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLd0m7_VYtBr",
        "outputId": "894e150b-9832-4e6b-d496-351f4c4c2d13"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "339\n",
            "624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 문서에서의 kite에 대한 TF 비교\n",
        "intro_tf = {}\n",
        "history_tf = {}\n",
        "intro_counts = Counter(intro_tokens) # intro 토큰 수(중복 허용)\n",
        "intro_tf['kite'] = intro_counts['kite'] / intro_total # intro TF\n",
        "history_counts = Counter(history_tokens) # history 토큰 수(중복 허용)\n",
        "history_tf['kite'] = history_counts['kite'] / history_total # history TF\n",
        "print(f'Term Frequency of \"kite\" in intro is: {intro_tf[\"kite\"]}')\n",
        "print(f'Term Frequency of \"kite\" in history is: {history_tf[\"kite\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D40Ik8s1awjl",
        "outputId": "51e18543-10f9-4662-df89-3c8ea4a5546a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Term Frequency of \"kite\" in intro is: 0.04129793510324484\n",
            "Term Frequency of \"kite\" in history is: 0.020833333333333332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (문제 발생) TF만으로 'kite'의 중요도를 판별하긴 어렵다.\n",
        "# (문제 해결) 역문서 빈도를 활용함.\n",
        "num_docs_containing_kite = 0\n",
        "num_docs_containing_and = 0\n",
        "num_docs_containing_china = 0\n",
        "\n",
        "for doc in [intro_tokens, history_tokens]:\n",
        "  if 'kite' in doc:\n",
        "    num_docs_containing_kite += 1\n",
        "  if 'and' in doc:\n",
        "    num_docs_containing_and += 1\n",
        "  if 'china' in doc:\n",
        "    num_docs_containing_china += 1\n",
        "#-----------------------------------------> 각 단어가 등장하는 문서 수를 다 셈.\n",
        "doc_len = 2\n",
        "\n",
        "print('kite IDF:', doc_len / num_docs_containing_kite) # 두 문서에서 모두 등장\n",
        "print('and IDF:', doc_len / num_docs_containing_and) # 두 문서에서 모두 등장\n",
        "print('china IDF:', doc_len / num_docs_containing_china) # 한 문서에서만 등장\n",
        "# 현재 문서 데이터 셋에서 'china'는 희귀하게 등장하는 단어임.\n",
        "# china 등장시 이 단어의 중요도를 올리자.\n",
        "# 그러면 이 문서에 대한 벡터를 뽑을 때, 이 문서의 특징을 더 잘 반영할 것임."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxstMJPQcXo8",
        "outputId": "149ebde3-081e-41ef-9237-2ca2d3971e3a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kite IDF: 1.0\n",
            "and IDF: 1.0\n",
            "china IDF: 2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF\n",
        "- TF와 IDF를 곱한 특징점으로서 단어의 출현 빈도와 특정 문서에서의 희귀도를 모두 고려한 NLP에서의 특징점이라고 할 수 있다.\n",
        "- 문서 -> 벡터화(BoW보다 효과적인 방식)"
      ],
      "metadata": {
        "id": "D-C5tDyRhPZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF\n",
        "intro_tf['and'] = intro_counts['and'] / intro_total\n",
        "history_tf['and'] = history_counts['and'] / history_total\n",
        "intro_tf['kite'] = intro_counts['kite'] / intro_total\n",
        "history_tf['kite'] = history_counts['kite'] / history_total\n",
        "intro_tf['china'] = intro_counts['china'] / intro_total\n",
        "history_tf['china'] = history_counts['china'] / history_total\n",
        "\n",
        "#IDF\n",
        "num_docs = 2\n",
        "intro_idf = {}\n",
        "history_idf = {}\n",
        "intro_idf['and'] = num_docs / num_docs_containing_and\n",
        "history_idf['and'] = num_docs / num_docs_containing_and\n",
        "intro_idf['kite'] = num_docs / num_docs_containing_kite\n",
        "history_idf['kite'] = num_docs / num_docs_containing_kite\n",
        "intro_idf['china'] = num_docs / num_docs_containing_china\n",
        "history_idf['china'] = num_docs / num_docs_containing_china"
      ],
      "metadata": {
        "id": "PP4MDgkgguxO"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF를 IDF가 좀 더 보정함.\n",
        "intro_tfidf = {}\n",
        "intro_tfidf['and'] = intro_tf['and'] * intro_idf['and']\n",
        "intro_tfidf['kite'] = intro_tf['kite'] * intro_idf['kite']\n",
        "intro_tfidf['china'] = intro_tf['china'] * intro_idf['china']\n",
        "\n",
        "history_tfidf = {}\n",
        "history_tfidf['and'] = history_tf['and'] * history_idf['and']\n",
        "history_tfidf['kite'] = history_tf['kite'] * history_idf['kite']\n",
        "history_tfidf['china'] = history_tf['china'] * history_idf['china']"
      ],
      "metadata": {
        "id": "qElgVby3j6M3"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intro_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkGEcQx7kdNB",
        "outputId": "e7225e67-8949-4e94-c7db-e5dd754c729b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 0.035398230088495575, 'kite': 0.04129793510324484, 'china': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hckLuncolVOI",
        "outputId": "d3916d58-04a9-4272-dc39-5a4e84e8c7e1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 0.03685897435897436,\n",
              " 'kite': 0.020833333333333332,\n",
              " 'china': 0.003205128205128205}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아래의 세 문장의 TF-IDF 벡터를 구하고, 주어진 쿼리에 대해 어떤 문장이 유사한지 계산하고자 함.\n",
        "doc0 = \"The faster Harry got to the store, the faster and faster Harry would get home.\"\n",
        "doc1 = \"Harry is hairy and faster than Jill.\"\n",
        "doc2 = \"Jill is not as hairy as Harry.\""
      ],
      "metadata": {
        "id": "NIwbnA_1laE4"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 문장의 TF-IDF 벡터 계산\n",
        "doc_tfidf_vectors = []\n",
        "docs = [doc0, doc1, doc2]\n",
        "\n",
        "for doc in docs:\n",
        "  vec = copy.copy(zero_vector)\n",
        "\n",
        "  tokens = tokenizer.tokenize(doc.lower()) # 토큰화\n",
        "  token_counts = Counter(tokens) # 단어에 대한 출현 횟수 == BoW\n",
        "\n",
        "  for key, val in token_counts.items(): # 각 토큰에 대해서 해당 토큰이 등장하는 문서를 센다.\n",
        "    docs_containing_key = 0\n",
        "    for _doc in docs:\n",
        "      if key in _doc:\n",
        "        docs_containing_key += 1\n",
        "    tf = val / len(tokens)\n",
        "    if docs_containing_key:\n",
        "      idf = len(docs) / docs_containing_key\n",
        "    else: # 모든 문서에 대해 해당 토큰이 등장하지 않음. (예외 처리)\n",
        "      idf = 0\n",
        "    vec[key] = tf * idf\n",
        "  doc_tfidf_vectors.append(vec)"
      ],
      "metadata": {
        "id": "YFGSYRVDme6s"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 주어진 질문에 대해 가장 유사한 문장 찾기\n",
        "# 질문 문장에 대한 TF-IDF 벡터 생성\n",
        "# Vocab에 없는 토큰에 대해서는 TF-IDF값을 생성할 수 없음.\n",
        "# 학습 데이터 셋에서 불용어 제거, 일부러 제거한 토큰들, query에는 Vocab에 없는 토큰이 등장할 수 있다.\n",
        "query = \"How long does it take to get to the store?\"\n",
        "query_vec = copy.copy(zero_vector)\n",
        "\n",
        "tokens = tokenizer.tokenize(query.lower())\n",
        "token_counts = Counter(tokens)\n",
        "\n",
        "for key, val in token_counts.items():\n",
        "  docs_containing_key = 0\n",
        "  for _doc in docs:\n",
        "    if key in _doc.lower():\n",
        "      docs_containing_key += 1\n",
        "  if docs_containing_key == 0: # Vocab에 없는 토큰은 tfidf 생성 못하게 함.\n",
        "    continue\n",
        "  tf = val / len(tokens)\n",
        "  idf = len(docs) / docs_containing_key\n",
        "  query_vec[key] = tf * idf\n",
        "query_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kg2bCSaoKkQ",
        "outputId": "d325dfaa-ca2c-4d4a-c789-7357bb954018"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([(',', 0),\n",
              "             ('.', 0),\n",
              "             ('and', 0),\n",
              "             ('as', 0),\n",
              "             ('faster', 0),\n",
              "             ('get', 0.2727272727272727),\n",
              "             ('got', 0),\n",
              "             ('hairy', 0),\n",
              "             ('harry', 0),\n",
              "             ('home', 0),\n",
              "             ('is', 0),\n",
              "             ('jill', 0),\n",
              "             ('not', 0),\n",
              "             ('store', 0.2727272727272727),\n",
              "             ('than', 0),\n",
              "             ('the', 0.2727272727272727),\n",
              "             ('to', 0.5454545454545454),\n",
              "             ('would', 0)])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 주어진 질문에 대해 가장 유사한 문장 찾기\n",
        "print(cosine_sim(query_vec, doc_tfidf_vectors[0]))\n",
        "print(cosine_sim(query_vec, doc_tfidf_vectors[1])) # query와 겹치는 토큰이 없다는 의미\n",
        "print(cosine_sim(query_vec, doc_tfidf_vectors[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZy16GI5p6VK",
        "outputId": "4cc644e4-8123-46e7-887b-34673f789375"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6132857433407974\n",
            "0.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF\n",
        "- (문제 발생) 이 간단한 공식을 가지고 검색 해결이 안되는 경우 발생\n",
        "- IDF의 기본적인 개념만 고려한다면, 전의 수행한 것과 같이 IDF를 계산해도 충분하지만, 실제로는 총 문서 수가 굉장히 많을 수 있다는 문제가 있음.\n",
        "- 문서 수가 굉장히 많으면, IDF의 값이 너무 커지는 문제가 발생한다.\n",
        "- (문제 해결) 정규화 방안으로 문서 수가 굉장히 많으면, log를 취한다.\n",
        "- 전체 문서에서 등장 횟수가 0인 단어가 있다면, IDF 분모가 0이 되므로 이를 예방하기 위해 분모에 1을 더해주는 형식이 주로 활용됨.\n",
        "- TF(term, document) = number of times term appears in document / total number of terms in document\n",
        "- IDF(term) = log(N / (1 + df))\n",
        "- TF-IDF(term, document) = TF(term, document) * IDF(term)"
      ],
      "metadata": {
        "id": "H_dgWPLmsPp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scikit-learn의 TfidfVectorizer 모델을 활용하여 쉽게 주어진 문서에 대해 TF-IDF 벡터 계산 및 분석 가능\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "corpus = [doc0, doc1, doc2]\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df=1)\n",
        "model = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(model.todense()) # TF-IDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zadmBHcGrY9B",
        "outputId": "7101a743-a6a9-4ba4-c1fe-d711e6910bac"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.1614879  0.         0.48446369 0.21233718 0.21233718 0.\n",
            "  0.25081952 0.21233718 0.         0.         0.         0.21233718\n",
            "  0.         0.63701154 0.21233718 0.21233718]\n",
            " [0.36930805 0.         0.36930805 0.         0.         0.36930805\n",
            "  0.28680065 0.         0.36930805 0.36930805 0.         0.\n",
            "  0.48559571 0.         0.         0.        ]\n",
            " [0.         0.75143242 0.         0.         0.         0.28574186\n",
            "  0.22190405 0.         0.28574186 0.28574186 0.37571621 0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BM25\n",
        "- Okapi BM25는 Okapi 정보 검색 시스템에 쓰인 query-document 매칭 기법임.\n",
        "- 오픈 소스 검색 엔진 중 가장 유명한 ElasticSearch에서도 현재 활용하고 있음.\n",
        "- TF-IDF는 단어, 문서가 변수로 들어가고 유사도 계산을 위해서 코사인 유사도 등을 계산을 해야한다.\n",
        "- TF-IDF의 목적: 문서 -> 벡터로 만드는 것\n",
        "- BM25는 문서, query가 변수로 들어가고 유사도가 결과로 나온다는 것에 유의\n",
        "- BM25의 목적: 문서, query가 입력 -> 유사도(점수)가 결과로 나옴.\n",
        "\n",
        "# BM25 vs TF-IDF\n",
        "- 1. BM25는 TF-IDF에 비해서 IDF 값은 문서 빈도가 증가함에 따라 더욱 급격히 감소시키고 심지어 음의 값을 갖게 만든다.\n",
        "- 2. BM25는 TF-IDF에 비해서 TF 관련 term의 경우, 용어 카운트가 늘어남에 따라 증가하는 정도를 saturation(만족, 수렴) 시켰다. -> 너무 극단적으로 급증하는 값을 완화함.\n",
        "- 3. BM25는 TF-IDF에 비해서 문서 길이가 늘어남에 따라 같은 용어 카운트에 대해 score가 감소하는 폭을 완화함.\n",
        "- TF-IDF는 벡터 형태로 나오는 것에 반해 BM25는 각 토큰들에 대해 계산한 점수를 합하므로 위와 같은 방식을 통해 구해진 각 토큰의 점수를 취합하여 쿼리-문서의 매칭 정도를 나타내는 방식이라고 할 수 있음."
      ],
      "metadata": {
        "id": "h82w2Ea2xu_m"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}