{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 의미의 학습\n",
        "  - 어떻게 의미에 대해서 학습해야 하나?\n",
        "    - 글 속에 숨은 의미를 분석하기 위해서는 단어 자체의 정의뿐만 아니라 아래와 같은 측면들을 고려해야 함.\n",
        "\n",
        "    - 단어 순서\n",
        "      - 같은 단어로 이루어진 문장이라도 순서가 달라지면, 뜻이 달라질 수 있음.\n",
        "\n",
        "    - 단어 간격\n",
        "      - 서로 수식하는 단어가 반드시 가까이 있지 않고, 문장 끝의 단어가 거의 맨 앞의 단어를 수식할 수 있으므로 다양한 간격의 단어에 대해서 상호 분석이 가능해야 함.\n",
        "\n",
        "  - 의미의 학습\n",
        "    - 단어들의 관계에서 의미를 찾기 위한 접근법은 크게 temporal(시간적) 방법과 spatial(공간적) 방법으로 나눌 수 있다.\n",
        "    \n",
        "    - temporal 방법\n",
        "      - 우리가 듣기를 수행하는 것과 유사하게 시간 순서대로 단어를 파악해나가며, 그 뜻을 분석해나가는 방식\n",
        "    \n",
        "    - spatial 방법\n",
        "      - 우리가 읽기를 수행할 때 사용하는 방식으로써 문장 전체를 자유롭게 오가며, 단어들을 파악하고 뜻을 분석해나가는 방식\n",
        "\n",
        "# 합성곱 신경망\n",
        "  - 합성곱 연산\n",
        "    - 합성곱 층(convolution layer)은 신경망 층 구성 방식의 한 종류로써 합성곱(convolution) 연산을 통해 다음 층에 내보낼 출력값을 계산함.\n",
        "\n",
        "    - 합성곱 연산에는 입력값 및 커널이 필요함.\n",
        "      - 합성곱 연산 과정\n",
        "        - 1. 입력값에 커널을 붙인다.\n",
        "        - 2. 커널을 한 칸씩 움직인다.\n",
        "        - 3. 입력값과 커널이 겹친 공간의 값들을 모두 각 위치까지 곱해서 더함.\n",
        "      - 일반적으로는 커널은 입력값보다 작은 크기를 갖고 있음.\n",
        "    \n",
        "    - 모든 연산을 마치고 나면 합성곱 신경망에서 합성곱 결과로 나온 값들을 특징 맵(feature map)이라고 함.\n",
        "    - stride: 커널이 움직이는 간격\n",
        "\n",
        "    - 기본적으로 1보다 큰 크기의 커널로 합성곱을 진행한 이후에는 feature map의 크기가 입력값보다 작아지게 됨.\n",
        "    - 딥 러닝에서는 layer를 충분히 깊게 쌓여야 저레벨 특징점으로부터 고레벨 특징점을 학습할 수 있으므로 이렇게 feature map 크기가 줄어드는 것은 문제가 될 수 있음.\n",
        "      - 만약 합성곱 이후에도 feature map 크기가 동일하다면 원하는 만큼 layer를 쌓을 수 있음.\n",
        "    \n",
        "    - 합성곱을 진행한 이후의 feature map 크기가 입력값과 동일하게 만들고 싶다면, 입력값 주변에 다른 값들을 둘러주어야 함.\n",
        "     - 합성곱 연산 시 입력값 주변에 값을 두르는 것을 padding이라고 함.\n",
        "\n",
        "    - 패딩 시에 입력하는 값은 주로 0을 활용하지만 상황에 따라 1또는 직접 지정한 값을 활용할 수 있음.\n",
        "\n",
        "    - 합성곱 연산을 수행하는 합성곱 층(convolution layer)을 위주로 이루어진 신경망 구조를 합성곱 신경망(CNN)이라고 함.\n",
        "\n",
        "    - 합성곱 신경망에서도 맨 마지막에 분류를 담당하는 레이어들은 MLP 형태를 사용함.\n",
        "\n",
        "    - 합성곱 층에서 편향을 추가할 수 있으며, 이 때 편향은 각 커널당 하나의 값이 있음.\n",
        "      - 해당 커널로부터 생성된 feature map의 모든 요소에 같은 값이 더해짐.\n",
        "    \n",
        "    - Feature map의 높이 및 너비 계산\n",
        "      - Output_height = floor((Input_height - Kernel_height + 2Padding / Stride) + 1)\n",
        "      - Output_width = floor((Input_width - Kernel_width + 2Padding / Stride) + 1)\n",
        "\n",
        "    - 3차원 텐서의 합성곱 연산\n",
        "      - 3개의 채널을 가진 컬러 이미지로부터 하나의 특징 맵을 만들기 위해 총 3개의 커널 필요\n",
        "      - 이를 일반화하면, 입력 텐서의 채널 수 만큼의 커널이 있어야 특징 맵 하나를 생성할 수 있음.\n",
        "      - 다수의 커널을 사용하면, 원하는 개수의 채널을 갖는 특징 맵을 생성할 수 있음.\n",
        "      - 어떤 합성곱 층에서 필요한 커널의 개수 = input 채널의 수 * 합성곱 층에서 생성할 출력 채널의 수\n",
        "    \n",
        "    - 합성곱 층의 가중치 매개변수 개수 계산\n",
        "      - 합성곱 층의 가중치 매개변수 개수 = 커널 하나에 들어가는 매개변수 개수 * 총 커널 개수\n",
        "      - 합성곱 층의 가중치 매개변수 개수 = (K_height * K_width) * (C_in * C_out)\n",
        "      = 커널 내 가중치 개수 * 커널의 개수\n",
        "\n",
        "    - Pooling\n",
        "      - 주어진 입력값에서 정보를 추출한 후 크기가 줄어든 특징 맵을 생성하는 연산의 일종\n",
        "        - max pooling, avg pooling 등이 있음.\n",
        "\n",
        "      - 저레벨 특징점들을 바탕으로 더 고레벨의 특징점을 학습하기 위해 필요한 과정\n",
        "        - 풀링을 통해 합성곱 신경망은 더 넓은 범위의 이미지를 분석할 수 있게 됨.\n",
        "        - 저레벨 특징점: CNN의 초기 계층에서 추출되는 단순한 형태의 시각적 요소이다. 이 특징들은 기본적인 피턴이나 간단한 구조를 인식하는데 도움을 준다.\n",
        "          - ex) 모서리, 선, 색상, 텍스처\n",
        "        - 중간 레벨 특징점: 중간 계층에서 추출되는 비교적 복잡한 패턴으로, 저레벨 특징들을 결합하여 더 복잡한 구조를 나타냄.\n",
        "          - ex) 모양, 코너, 곡선\n",
        "        - 고레벨 특징점: CNN의 후반 계층에서 추출되는 특징으로, 보다 추상적이고 복잡한 구조나 개념적 요소를 인식할 수 있게 함. 이는 저레벨 특징과 중간 레벨 특징을 결합하여 CNN이 최종적인 객체나 개념을 파악할 수 있도록 함.\n",
        "\n",
        "# NLP를 위한 합성곱 신경망\n",
        "  - NLP에서 합성곱 신경망을 사용할 때는 단어 벡터들을 입력으로 사용함.\n",
        "    - 벡터들을 쌓아서 2차원의 입력이 만들어지게 되지만, 이 때 중요한 것은 단어들 사이의 관계이며 한 단어 벡터 내에서 다른 성분끼리 비교하는 것은 크게 중요치 않음.\n",
        "  - 즉, NLP에서 문장 입력에 대해 합성곱을 한다면, 1차원 합성곱 연산을 하는 것으로 해석 가능\n",
        "  - 크기가 2인 커널에 대해서 1차원 합성곱을 수행한다면,\n",
        "    - 1. 커널은 2차원 형태이지만 합성곱 연산이 일어나는 방향은 한 방향으로만 움직이게 되므로 1D 합성곱이라고 함.\n",
        "    - 2. 커널의 최종 shape은 (커널 크기, 임베딩 차원 수)\n",
        "  - 커널의 크기가 달라지면 한 번에 비교할 수 있는 단어 수가 달라지기 때문에 다른 n그램에 대한 분석 결과를 도출한다고 볼 수 있음\n",
        "  - 합성곱을 통해 특징을 추출할 때, 다양한 크기의 커널을 사용한다면 다양한 n그램 정보에 대해 분석할 수 있게 됨.\n",
        "  - 추출된 특징들을 기반으로 풀링 연산을 통해 가장 중요한 정보만 남기도록 함.\n",
        "    - 다만 이와 같이 연산을 수행하면 가중치 개수가 적어 신경망의 전체적인 근사 능력이 떨어질 수 있으므로, 같은 크기의 필터를 여러 개를 써서 이러한 단점을 보완함.\n",
        "  - 풀링 진행된 값들은 하나의 벡터로 연결되고, 마지막 fully connected layer를 통해 최종 값을 도출하는 구조임."
      ],
      "metadata": {
        "id": "hGxP6qBmEUIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IDMD 데이터 셋(영화 리뷰에 대한 감성 분석) 감성 분석 구현\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "39jL9bysWiaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a737aa-9e40-4ec2-960a-c4e8f78b0f2e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#zip 파일 현재 폴더로 복사, 중간 부분은 파일명에 따라 변경 필요\n",
        "!cp '/content/drive/MyDrive/IMDB Dataset.csv' ./"
      ],
      "metadata": {
        "id": "NB0e2G36XHzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e56b8c8f-8551-4e5d-cdb3-f0f895dbae5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjx4FMFw1HnK",
        "outputId": "cd37e74e-bec7-425e-c878-5a4d2d49cca0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_csv = 'IMDB Dataset.csv'\n",
        "df = pd.read_csv(base_csv)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4474omxC6eAy",
        "outputId": "532f4bf1-411b-4727-e4bc-4bddd9a4b599"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-830f1a13-433f-41b4-9652-6d4243d1e313\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-830f1a13-433f-41b4-9652-6d4243d1e313')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-830f1a13-433f-41b4-9652-6d4243d1e313 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-830f1a13-433f-41b4-9652-6d4243d1e313');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7203dd9f-f246-49c5-988b-9c2952c5083d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7203dd9f-f246-49c5-988b-9c2952c5083d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7203dd9f-f246-49c5-988b-9c2952c5083d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-process the dataset\n",
        "X,y = df['review'].values,df['sentiment'].values\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
        "print(f'shape of train data is {x_train.shape}') # train set\n",
        "print(f'shape of test data is {x_test.shape}') # test set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2QHBH2E6f9L",
        "outputId": "0c4b87c2-c574-4cde-8f14-7d9c7db2b65d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train data is (40000,)\n",
            "shape of test data is (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본적인 전처리 함수\n",
        "def preprocess_string(s):\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Replace all runs of whitespaces with no space\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    # replace digits with no space\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "    return s\n",
        "\n",
        "# 토큰화 및 단어 사전 생성, 단어를 인덱스로 변환 및 label을 인덱스로 변환\n",
        "# dataset을 만드는 함수\n",
        "def tokenize(x_train,y_train,x_val,y_val):\n",
        "    word_list = []\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    for sent in x_train:\n",
        "        for word in sent.lower().split():\n",
        "            word = preprocess_string(word)\n",
        "            if word not in stop_words and word != '':\n",
        "                word_list.append(word)\n",
        "\n",
        "    corpus = Counter(word_list)\n",
        "    # sorting on the basis of most common words\n",
        "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000] # 빈도가 높은 1000개 토큰까지만 자른다.\n",
        "    # creating a dict\n",
        "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
        "\n",
        "    # tokenize\n",
        "    final_list_train,final_list_test = [],[]\n",
        "    for sent in x_train:\n",
        "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n",
        "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
        "    for sent in x_val:\n",
        "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n",
        "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
        "\n",
        "    encoded_train = [1 if label =='positive' else 0 for label in y_train]\n",
        "    encoded_test = [1 if label =='positive' else 0 for label in y_val]\n",
        "    return final_list_train, np.array(encoded_train), final_list_test, np.array(encoded_test),onehot_dict"
      ],
      "metadata": {
        "id": "Fxv7sV7S7JcG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수 호출을 통해 정의된 연산들 수행\n",
        "# 단어 사전의 길이를 확인해보면 1000임을 알 수 있음.\n",
        "x_train,y_train,x_test,y_test,vocab = tokenize(x_train,y_train,x_test,y_test)\n",
        "print(f'Length of vocabulary is {len(vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsYcPxnM7bOi",
        "outputId": "131f9cd1-1a33-4f86-daa7-9ebe5b4cc11a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of vocabulary is 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터셋에서 각 데이터의 단어 수(문장 내 단어 수)에 대해 통계를 내보면 아래와 같이 나옴.\n",
        "# 대부분의 데이터들을 모두 포함 가능한 200단어까지를 길이 상한으로 설정 예정\n",
        "rev_len = [len(i) for i in x_train]\n",
        "pd.Series(rev_len).hist()\n",
        "plt.show()\n",
        "pd.Series(rev_len).describe()\n",
        "# x축: 전처리 후 문장 길이\n",
        "# y축: 문장 개수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "pKLdLlBq7dmN",
        "outputId": "209c3ec7-eeb6-48e5-d553-af6e94ecbbe3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    40000.000000\n",
              "mean        69.246175\n",
              "std         48.303060\n",
              "min          2.000000\n",
              "25%         39.000000\n",
              "50%         54.000000\n",
              "75%         84.000000\n",
              "max        656.000000\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>69.246175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>48.303060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>39.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>54.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>84.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>656.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 200 단어에 맞추어 모든 데이터를 다시 정리\n",
        "# 200 단어보다 더 짧은 데이터는 앞쪽 index들을 0으로 채우고나서 각 단어의 index를 채워서 길이 200을 맞춤.\n",
        "# 200 단어보다 더 긴 데이터는 뒤쪽 부분을 버리게 됨.\n",
        "def padding_(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features\n",
        "\n",
        "x_train_pad = np.array(padding_(x_train,200))\n",
        "x_test_pad = np.array(padding_(x_test,200))"
      ],
      "metadata": {
        "id": "fuubvvew7ywH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 길이까지 정리된 데이터를 이용해 데이터셋 및 데이터로더 생성\n",
        "# 데이터를 index의 리스트 형태로 numpy array에 저장했으므로 TensorDataset 생성 가능\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "5NdJBvZs77C8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더로부터 샘플링하여 데이터 직접 확인\n",
        "# Batch size가 50이므로 50개의 데이터에 대해 출력됨.\n",
        "\n",
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print('Sample input: \\n', sample_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkU3S88s79N_",
        "outputId": "58f4c99b-56b9-4446-bb3b-cbceb663b6fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input: \n",
            " tensor([[ 37,  15,   4,  ...,  75,   9, 833],\n",
            "        [  0,   0,   0,  ..., 330,   9, 186],\n",
            "        [  0,   0,   0,  ...,  15,  55, 690],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 553,  75,  15],\n",
            "        [  0,   0,   0,  ...,  97,  26, 229],\n",
            "        [  0,   0,   0,  ..., 325,  65,   2]])\n",
            "Sample input: \n",
            " tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
            "        0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "        1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN 모델 구현\n",
        "- 커널 크기는 2, 3, 4, 5 네 가지를 사용하며, 각 커널은 100개의 특징 맵을 생성토록 함.\n",
        "- 워드 임베딩은 자연어 처리 연구에 여전히 널리 활용되고 있으나, 딥러닝 기반의 자연어 처리 연구에서는 워드 임베딩을 따로 학습해서 사용하기보다는 딥러닝 모델에 엮인 학습 가능한 임베딩 lookup table을 주로 이용함.\n",
        "- nn.Embedding은 이와 같은 임베딩 lookup table을 구현한 클래스이며, word -> Integer -> lookup table -> Embedding vector 같은 구조로 학습.\n",
        "- 이미지와 달리 임베딩 lookup table은 입력값까지 역전파가 진행되는 것이 특징임."
      ],
      "metadata": {
        "id": "LZrof-uwEzzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NLP_CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, output_size, embedding_dim, num_filters=100, kernel_sizes=[2,3,4,5], dropout_prob=0.5):\n",
        "    super(NLP_CNN, self).__init__()\n",
        "\n",
        "    self.num_filters = num_filters\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    self.convs = nn.ModuleList([\n",
        "        nn.Conv2d(1, num_filters, (k, embedding_dim)) for k in kernel_sizes\n",
        "    ])\n",
        "\n",
        "    self.fc = nn.Linear(len(kernel_sizes) * num_filters, output_size)\n",
        "    self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embeds = self.embedding(x) # (batch_size, seq_length, embedding_dim)\n",
        "\n",
        "    embeds = embeds.unsqueeze(1) # (batch_size, 1, seq_length, embedding_dim)\n",
        "    conv_results = [F.relu(conv(embeds)).squeeze(3) for conv in self.convs] # (batch_size, num_filters, seq_length - conv_size + 1, 1) -> (batch_size, num_filters, seq_length - conv_size + 1)\n",
        "    pool_results = [F.max_pool1d(fm, fm.size(2)).squeeze(2) for fm in conv_results] # (batch_size, num_filters, 1) -> (batch_size, num_filters)\n",
        "\n",
        "    x = torch.cat(pool_results, 1)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    logit = self.fc(x)\n",
        "\n",
        "    return logit"
      ],
      "metadata": {
        "id": "qQGcYOMrGsIs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 100\n",
        "model = NLP_CNN(len(vocab)+1, 2, embed_dim).to(device)"
      ],
      "metadata": {
        "id": "bEQGd4tQkkgb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, data_loader):\n",
        "  model.train()\n",
        "  train_loss = 0\n",
        "  for i, (x, y) in enumerate(data_loader):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logit = model(x)\n",
        "    loss = criterion(logit, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item() * x.size(0)\n",
        "  return train_loss / len(data_loader.dataset)"
      ],
      "metadata": {
        "id": "e5TU12OAlB7e"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader):\n",
        "  model.eval()\n",
        "  corrects, total_loss = 0, 0\n",
        "  for i, (x, y) in enumerate(data_loader):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    logit = model(x)\n",
        "    corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "  size = len(data_loader.dataset)\n",
        "\n",
        "  avg_accuracy = 100.0 * corrects / size\n",
        "  return avg_accuracy"
      ],
      "metadata": {
        "id": "bdVKQr5soWqn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "lr = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for e in range(1, num_epochs + 1):\n",
        "  train_loss = train(model, criterion, optimizer, train_loader)\n",
        "  test_accuracy = evaluate(model, test_loader)\n",
        "\n",
        "  print(f\"[Epoch: {e:d}] train loss: {train_loss:5.2f} | test accuarcy: {test_accuracy:5.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLS6Vko7K_VQ",
        "outputId": "829b6666-90da-4970-eb4f-b2e4f08faf95"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1] train loss:  0.40 | test accuarcy: 84.07\n",
            "[Epoch: 2] train loss:  0.36 | test accuarcy: 83.93\n",
            "[Epoch: 3] train loss:  0.35 | test accuarcy: 85.19\n",
            "[Epoch: 4] train loss:  0.32 | test accuarcy: 85.29\n",
            "[Epoch: 5] train loss:  0.30 | test accuarcy: 85.22\n",
            "[Epoch: 6] train loss:  0.28 | test accuarcy: 85.14\n",
            "[Epoch: 7] train loss:  0.25 | test accuarcy: 84.73\n",
            "[Epoch: 8] train loss:  0.22 | test accuarcy: 84.63\n",
            "[Epoch: 9] train loss:  0.19 | test accuarcy: 85.15\n",
            "[Epoch: 10] train loss:  0.17 | test accuarcy: 85.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lZ6uIHfnOOno"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}